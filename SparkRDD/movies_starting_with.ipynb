{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "#For accessing files\nf = open('accessfiles.py', 'wb')\nf.write(streaming_body_1.read())\n\nimport accessfiles"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting pyspark==2.4.5\n  Downloading pyspark-2.4.5.tar.gz (217.8 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 217.8 MB 11 kB/s  eta 0:00:017    |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                  | 91.0 MB 9.8 MB/s eta 0:00:13     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589        | 162.2 MB 9.7 MB/s eta 0:00:06     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b     | 181.0 MB 9.9 MB/s eta 0:00:04\n\u001b[?25hCollecting py4j==0.10.7\n  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 197 kB 40.3 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=12ad945a5aebe1efbabad077ee6b53ac2855faf971f2cb1938c0500bd68429e1\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/01/c0/03/1c241c9c482b647d4d99412a98a5c7f87472728ad41ae55e1e\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.7 pyspark-2.4.5\n"
                }
            ],
            "source": "!pip install pyspark==2.4.5\n"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "from zipfile import ZipFile\nimport time\nimport numpy as np\nfrom operator import add\n\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SQLContext, SparkSession\nfrom pyspark.sql.types import StructType, StructField, DoubleType, IntegerType, StringType\n\nimport os\nfrom pyspark.sql.functions import unix_timestamp, to_date\nimport pyspark.sql.functions as F\n\nsc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n\nspark = SparkSession \\\n    .builder \\\n    .getOrCreate()\n\nspark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n\nfrom accessfiles import load_files\n\nload_files()"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "movies_rdd=sc.textFile(\"movies.dat\")\nmovies=movies_rdd.map(lambda lines: lines.split(\"::\")[1])\nstring_flat=movies.map(lambda lines: lines.split(\" \")[0])\n\n## filter first characters for a letter then find the count\nmovies_letter=string_flat.filter(lambda word: word.isalpha()).map(lambda word: (word[0].lower(),1))\nmovies_letter_count=movies_letter.reduceByKey(lambda x,y:x+y).sortByKey()\n\n## check for the first character for a digit then find the count\nmovies_digit=string_flat.filter(lambda word: word.isdigit()).map(lambda word: (word[0],1))\nmovies_digit_count=movies_digit.reduceByKey(lambda x,y:x+y).sortByKey()\n\n## Union the partitions into a same file\nresult_rdd=movies_digit_count.union(movies_letter_count).repartition(1)\n\n## Save the result into a pandas dataframe\nresult_df = result_rdd.toDF().toPandas()\nresult_df.columns = ['starts with','No. of movies']\n"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<a download=\"Movies_starting_with.csv\" href=\"data:text/csv;base64,c3RhcnRzIHdpdGgsTm8uIG9mIG1vdmllcwoxLDUKMiw2CjMsMwo0LDIKNSwyCjgsNAphLDE4NwpiLDMwMwpjLDIxNQpkLDE2MgplLDg0CmYsMTc2CmcsMTMzCmgsMTY2CmksODcKaiw1NwprLDU4CmwsMTYzCm0sMjQxCm4sMTAzCm8sNzIKcCwxNzYKcSwxMQpyLDE0NQpzLDM1MAp0LDIxNQp1LDI5CnYsMzEKdywxMjIKeCwxCnksMTYKeiw2Cg==\" target=\"_blank\">Download CSV file</a>",
                        "text/plain": "<IPython.core.display.HTML object>"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from accessfiles import create_download_link\ncreate_download_link(result_df, filename='Movies_starting_with.csv')"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}